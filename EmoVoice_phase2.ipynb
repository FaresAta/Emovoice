{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbde4b6",
   "metadata": {},
   "source": [
    "# Facial emotion recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30eab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_model = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaead9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "capture = cv2.VideoCapture(\"anyvideo\")\n",
    "\n",
    "#the loop depends on the frame rate\n",
    "for i in range(1800):\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        break  # If no frame is read, break the loop\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_model.detectMultiScale(gray_frame, 1.1, 5)\n",
    "\n",
    "    for (x, y, width, height) in faces:\n",
    "        face_roi = frame[y:y+height, x:x+width]  # Extract the face region of interest\n",
    "\n",
    "        try:\n",
    "            # Analyzing the face within the region of interest\n",
    "            emotion = DeepFace.analyze(face_roi, actions=[\"emotion\"], enforce_detection=False)\n",
    "            dominant_emotion = emotion[0][\"dominant_emotion\"]\n",
    "            cv2.putText(frame, dominant_emotion, (x, y + height + 20), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 225), 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (255, 255, 0), 2)\n",
    "        except Exception as e:\n",
    "            print(\"Error processing face:\", str(e))\n",
    "\n",
    "    frame_list.append(frame)  # Append the processed frame to the list\n",
    "\n",
    "    if i == 0:  # Get video size from the first frame\n",
    "        height, width, layers = frame.shape\n",
    "        size = (width, height)\n",
    "\n",
    "# Release the capture after processing\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"Emotions.avi\"\n",
    "output = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*\"DIVX\"), 60, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1a06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in range(len(frame_list)):\n",
    "  output.write(frame_list[frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef9f215",
   "metadata": {},
   "source": [
    "# Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd43747",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = \"Zb5kuD44u2ssacFvZCBQn5pSK5hH5cYzaSlIz3wKLcFt\"\n",
    "url = \"https://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/9db59064-2906-44af-9e56-da50a4c6bfab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator(apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stt = SpeechToTextV1(authenticator = authenticator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be547e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "stt.set_service_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5beddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess \n",
    "import os\n",
    "\n",
    "#here we split the audio files into small groups\n",
    "command = 'ffmpeg -i watsonx.mp4 -vn -ar 44100 -ac 2 -b:a 192k audio.mp3'\n",
    "subprocess.call(command, shell=True)\n",
    "command = 'ffmpeg -i audio.mp3 -f segment -segment_time 360 -c copy %03d.mp3'\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ba436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we go through the audio files\n",
    "files = []\n",
    "for filename in os.listdir('.'):\n",
    "    if filename.endswith(\".mp3\") and filename !='audio.mp3':\n",
    "        files.append(filename)\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15366f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for filename in files:\n",
    "    with open(filename, 'rb') as f:\n",
    "        res = stt.recognize(audio=f, content_type='audio/mp3', model='en-US_NarrowbandModel', inactivity_timeout=360).get_result()\n",
    "        results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "textt = []\n",
    "for file in results:\n",
    "    for result in file['results']:\n",
    "        textt.append(result['alternatives'][0]['transcript'].rstrip() + '.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "textt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save a text in a file\n",
    "with open('output.txt', 'w') as out:\n",
    "    out.writelines(textt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a417dc42",
   "metadata": {},
   "source": [
    "# NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71528f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read the text from the file\n",
    "file_path = 'output.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    textt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd409a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, EntitiesOptions, KeywordsOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bfb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator('Acws9345wBrFv-Adehqt9MOXYFiG9SHRx76Kh_d457r4')\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2022-04-07',\n",
    "    authenticator=authenticator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745cab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_language_understanding.set_service_url('https://api.us-south.natural-language-understanding.watson.cloud.ibm.com/instances/94c4168e-20b7-4605-84dc-658a93875153')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = natural_language_understanding.analyze(\n",
    "    text=textt,\n",
    "    features=Features(\n",
    "        entities=EntitiesOptions(emotion=True, sentiment=True),\n",
    "        keywords=KeywordsOptions(emotion=True, sentiment=True))).get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(response, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
