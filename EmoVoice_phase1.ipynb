{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = cv2.imread(\"Training/3/Training_1206.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe61401",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74976af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadirectory = \"Training/\" #the new file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all the images\n",
    "for category in Classes:\n",
    "    path = os.path.join(Datadirectory, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img))\n",
    "        plt.imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6471078",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224 # for transfer learning\n",
    "new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "plt.imshow(cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772561c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all images and convert them to array\n",
    "\n",
    "training_Data = [] # data array\n",
    "\n",
    "def create_training_Data():\n",
    "    for category in Classes:\n",
    "        path = os.path.join(Datadirectory, category)\n",
    "        class_num = Classes.index(category) #01, ## Label\n",
    "        for img in os.listdir(path): \n",
    "            try:\n",
    "                img_array = cv2.imread(os.path. join(path, img))\n",
    "                new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                training_Data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to shuffle the sequence of the pics for trainig\n",
    "\n",
    "import random \n",
    "random.shuffle(training_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a253f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] #data / features\n",
    "y = [] # label\n",
    "\n",
    "for features, label in training_Data:\n",
    "    X.append(features) # this one contains the array(images)\n",
    "    y.append(label) # this one contains the labels\n",
    "\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 3) #converting to 4 dimension for library parameters purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e42b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab57a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61356139",
   "metadata": {},
   "source": [
    "# deep learning training - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14509ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a308a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb63f93",
   "metadata": {},
   "source": [
    "# Transfer Learning - Tuning, weights will start from last chech point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88751848",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input = model.input # input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output = model.layers[-2].output  #this is to ignore the last layer because we have 7 classes not 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0961c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = layers.Dense(128)(base_output) # adding new layer after the global pooling layer\n",
    "final_output = layers.Activation(\"relu\")(final_output) # activation function\n",
    "final_output = layers.Dense(64)(final_output)\n",
    "final_output = layers.Activation(\"relu\")(final_output)\n",
    "final_output = layers.Dense(7, activation = \"softmax\")(final_output) # I have 7 classes , I used sofmatx because this is my classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9943013",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ed78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.Model(inputs = base_input, outputs = final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7493e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247add1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model.fit(X, Y, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"happy.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99596fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "for x,y,w,h in faces:\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = frame[y:y+h, x:x+w]\n",
    "    cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    facess = faceCascade.detectMultiScale(roi_gray)\n",
    "    if len(facess) == 0:\n",
    "        print(\"face not detected\")\n",
    "    else:\n",
    "        for (ex,ey,ew,eh) in facess:\n",
    "            face_roi = roi_color[ey: ey+eh, ex:ex+ew]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e3f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c623bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3662e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image = cv2.resize(face_roi, (224, 224))\n",
    "final_image = np.expand_dims(final_image, axis = 0)\n",
    "final_image = final_image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f35df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b68a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
